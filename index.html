<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0,user-scalable=no">
  <meta name=”twitter:card” content=”summary“>
  <meta name=”twitter:site” content=”@_riceham“>
  <meta property='og:type' content="website">
  <meta property='og:title' content="Source-Filter HiFi-GAN Demo">
  <meta property='og:url' content="https://chomeyama.github.io/SiFiGAN-Demo/">
  <meta property='og:description' content="Project demo page.">
  <meta property="og:image" content="img/me2.jpg">
  <meta name="description" content="Source-Filter HiFi-GAN Demo">
  <title>Source-Filter HiFi-GAN</title>
  <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Material+Icons+Outlined" rel="stylesheet">
  <link href="css/style.css" media="all" rel="stylesheet" type="text/css">
  <link rel="shortcut icon" href="img/me2.ico">
  <link rel=”canonical” href=”https://chomeyama.github.io/Profile/”>
</head>

<body>

  <div class="container">

    <header class="header">
      <h2><a href="https://chomeyama.github.io/Profile/">Reo YONEYAMA / Home</a></h2>
      <nav class="pc-nav">
        <ul id="nav">
          <li id="nav"><a href="#abstract">Abstract</a></li>
          <li id="nav"><a href="#demo">Demo</a></li>
          <li id="nav"><a href="#citation">Citation</a></li>
        </ul>
      </nav>
      <nav class="sp-nav">
        <ul id="sp-nav">
          <li id="sp-nav"><a href="#abstract">Abstract</a></li>
          <li id="sp-nav"><a href="#demo">Demo</a></li>
          <li id="sp-nav"><a href="#citation">Citation</a></li>
          <li class="close"><span>Close</span></li>
        </ul>
      </nav>
      <div id="hamburger">
        <span></span>
      </div>
    </header>

    <div class="main">

      <div class="paper_info">
        <h1>Source-Filter HiFi-GAN: Fast and Pitch Controllable High-Fidelity Neural Vocoder</h1>
        <h2 class="author">Reo Yoneyama<sup>1</sup>, <a href="https://bigpon.github.io/">Yi-Chiao Wu<sup>2</sup></a>,
          and <a href="https://sites.google.com/site/tomokitoda/">Tomoki Toda<sup>1</sup></a></h2>
        <h2><sup>1</sup>Nagoya University, Japan, <sup>2</sup>Meta Reality Labs Research, USA</h2>
        <h2 style="margin-top: 10px;">Submitted to <a href="">ICASSP 2023</a>
        </h2>
      </div>

      <h2 class="sectitle">Abstract</h2>
      <div id="abstract" class="section">
        <p align="justify">
          Our previous work, the unified source-filter GAN (uSFGAN) vocoder, introduced a novel architecture based on
          the source-filter theory into the parallel waveform generative adversarial network to achieve high voice
          quality and pitch controllability. However, the high temporal resolution inputs result in high computation
          costs. Although the HiFi-GAN vocoder achieves fast high-fidelity voice generation thanks to the efficient
          upsampling-based generator architecture, the pitch controllability is severely limited. To realize a fast and
          pitch-controllable high-fidelity neural vocoder, we introduce the source-filter theory into HiFi-GAN by
          hierarchically conditioning the resonance filtering network on a well-estimated source excitation information.
          According to the experimental results, our proposed method outperforms HiFi-GAN and uSFGAN on a singing voice
          generation in voice quality and synthesis speed on a single CPU. Furthermore, unlike the uSFGAN vocoder, the
          proposed method can be easily adopted/integrated in real-time applications and end-to-end systems.
        </p>
        <h3 style="text-align: center;">[<a href="https://arxiv.org/abs/2210.15533">Arxiv</a>]
          [<a href="https://github.com/chomeyama/SiFiGAN">Code</a>]
        </h3>
      </div>

      <div class="images1">
        <figure>
          <img src="img/sifigan.png" alt="SiFiGAN architecture" title="SiFiGAN architecture">
          <figcaption>SiFi-GAN comprises the source-network (left) and filter-network (right). Conv, T.Conv,
            QP-ResBlock, and MRF denote 1D convolution, transposed 1D convolution, quasi-periodic residual block, and
            multi-receptive
            fusion [1], respectively. d, a, and Fs denote dilation sizes, the dense factor [2], and the sampling rate in
            Hz, respectively.</figcaption>
        </figure>
      </div>
      <div class="images1">
        <figure>
          <img src="img/results.png" alt="results" title="results">
          <figcaption>Results of objective and subjective evaluations. The MOS of the ground truth samples was 3.99 ±
            0.05 (1.0 x F<sub>0</sub>). Real time factors (RTFs) were computed with 108 clips (totally 878 s) on a
            single AMD EPYC 7542 or GeForce RTX 3090. The RTFs of the vanilla HiFi-GAN were 0.84 on the CPU and 3.0 x
            10<sup>-3</sup> on the GPU.
          </figcaption>
        </figure>
      </div>
      <div class="images1">
        <figure>
          <img src="img/spec.png" alt="spectrogram comparison" title="spectrogram comparison">
          <figcaption>Spectrograms of output singing voices from SiFi-GAN (left) and SiFi-GAN Direct (right),
            respectively.
          </figcaption>
        </figure>
      </div>

      <h2 class="sectitle">Demo</h2>
      <div id="demo" class="section">
        <p>
          Only Namine Ritsu [3] database is used for the training. All vocoders are conditioned on WORLD [4] features.
          All provided samples are unseen songs in the training.<br>

          <b>Model details</b>
        <ul>
          <li>WORLD : A conventional source-filter vocoder [4].</li>
          <li>hn-uSFGAN : Harmonic-plus-noise unified source-filter GAN [5]. Please check the <a
              href="https://chomeyama.github.io/HN-UnifiedSourceFilterGAN-Demo/">DEMO</a> for more information.</li>
          <li>HiFi-GAN : The vanilla HiFi-GAN (V1) [1] conditioned on the WORLD features.</li>
          <li>HiFi-GAN + Sine : HiFi-GAN (V1) conditioned on the WORLD features and the sine embedding through
            downsampling CNNs [6-8].</li>
          <li>HiFi-GAN + Sine + QP : Extended HiFi-GAN + Sine model by inserting QP-ResBlocks after each transposed CNN.
          </li>
          <li>SiFi-GAN : Proposed source-filter HiFi-GAN.</li>
          <li>SiFi-GAN Direct : SiFi-GAN without 2nd downsampling CNNs. In this model, the source excitation
            representations from each QP-ResBlock are directly fed to filter-network at the corresponding temporal
            resolution without passing downsampling CNNs.</li>
        </ul>
        <br>
        </p>

        <div class="selects">
          <label for="utt_id">Utterance ID</label>
          <div class="simple_select">
            <select required id="utt_id" name="utt_id">
              <option value="namine_ritsu_1st_color_seg1">1st_color_seg1</option>
              <option value="namine_ritsu_1st_color_seg18">1st_color_seg18</option>
              <option value="namine_ritsu_ARROW_seg5">ARROW_seg5</option>
              <option value="namine_ritsu_ARROW_seg13">ARROW_seg13</option>
              <option value="namine_ritsu_BC_seg2">BC_seg2</option>
              <option value="namine_ritsu_BC_seg20" selected>BC_seg20</option>
              <option value="namine_ritsu_Closetoyou_seg5">Closetoyou_seg5</option>
              <option value="namine_ritsu_Closetoyou_seg24">Closetoyou_seg24</option>
              <option value="namine_ritsu_ERROR_seg3">ERROR_seg3</option>
              <option value="namine_ritsu_ERROR_seg21">ERROR_seg21</option>
            </select>
          </div>

          <div class="button">
            <input type="button" value="OK" onclick="clickBtn()">
          </div>
        </div>

        <script>
          function clickBtn() {
            var utt_id = document.getElementById('utt_id');
            utt_id.options[utt_id.selectedIndex].selected = true;
            document.getElementById("natural_f1.00").src = "audio/" + "natural" + "/" + utt_id.value + "_f1.00.wav";
            const methods = ["world", "hnusfgan", "hifigan", "hifigan.sine", "hifigan.sine.qp", "sifigan", "sifigan.abl"];
            const f0_factors = ["_f0.50", "_f0.71", "_f1.00", "_f1.41", "_f2.00"];
            for (const m of methods) {
              for (const f of f0_factors) {
                document.getElementById(m + f).src = "audio/" + m + "/" + utt_id.value + f + ".wav";
              }
            }
          }
        </script>

        <table class="audio_table">
          <thead>
            <tr>
              <th style="text-align: center" class="td_fixed">Model</th>
              <th style="text-align: center">Copy Synthesis</th>
              <th style="text-align: center">F<sub>0</sub> x 2<sup>-1.0</sup></th>
              <th style="text-align: center">F<sub>0</sub> x 2<sup>-0.5</sup></th>
              <th style="text-align: center">F<sub>0</sub> x 2<sup>0.5</sup></th>
              <th style="text-align: center">F<sub>0</sub> x 2<sup>1.0</sup></th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td style="text-align: left" class="td_fixed">Natural</td>
              <td style="text-align: center"><audio id="natural_f1.00"
                  src="audio/natural/namine_ritsu_BC_seg20_f1.00.wav" controls="" preload=""></audio>
              <td style="text-align: center"><audio src="" preload=""></audio></td>
              <td style="text-align: center"><audio src="" preload=""></audio></td>
              <td style="text-align: center"><audio src="" preload=""></audio></td>
              <td style="text-align: center"><audio src="" preload=""></audio></td>
              </td>
            </tr>
            <tr>
              <td style="text-align: left" class="td_fixed">WORLD</td>
              <td style="text-align: center"><audio id="world_f1.00" src="audio/world/namine_ritsu_BC_seg20_f1.00.wav"
                  controls="" preload=""></audio>
              </td>
              <td style="text-align: center"><audio id="world_f0.50" src="audio/world/namine_ritsu_BC_seg20_f0.50.wav"
                  controls="" preload=""></audio>
              </td>
              <td style="text-align: center"><audio id="world_f0.71" src="audio/world/namine_ritsu_BC_seg20_f0.71.wav"
                  controls="" preload=""></audio>
              </td>
              <td style="text-align: center"><audio id="world_f1.41" src="audio/world/namine_ritsu_BC_seg20_f1.41.wav"
                  controls="" preload=""></audio>
              </td>
              <td style="text-align: center"><audio id="world_f2.00" src="audio/world/namine_ritsu_BC_seg20_f2.00.wav"
                  controls="" preload=""></audio>
              </td>
            </tr>
            <tr>
              <td style="text-align: left" class="td_fixed">hn-uSFGAN</td>
              <td style="text-align: center"><audio id="hnusfgan_f1.00"
                  src="audio/hnusfgan/namine_ritsu_BC_seg20_f1.00.wav" controls="" preload=""></audio>
              </td>
              <td style="text-align: center"><audio id="hnusfgan_f0.50"
                  src="audio/hnusfgan/namine_ritsu_BC_seg20_f0.50.wav" controls="" preload=""></audio>
              </td>
              <td style="text-align: center"><audio id="hnusfgan_f0.71"
                  src="audio/hnusfgan/namine_ritsu_BC_seg20_f0.71.wav" controls="" preload=""></audio>
              </td>
              <td style="text-align: center"><audio id="hnusfgan_f1.41"
                  src="audio/hnusfgan/namine_ritsu_BC_seg20_f1.41.wav" controls="" preload=""></audio>
              </td>
              <td style="text-align: center"><audio id="hnusfgan_f2.00"
                  src="audio/hnusfgan/namine_ritsu_BC_seg20_f2.00.wav" controls="" preload=""></audio>
              </td>
            </tr>
            <tr>
              <td style="text-align: left" class="td_fixed">HiFi-GAN</td>
              <td style="text-align: center"><audio id="hifigan_f1.00"
                  src="audio/hifigan/namine_ritsu_BC_seg20_f1.00.wav" controls="" preload=""></audio>
              </td>
              <td style="text-align: center"><audio id="hifigan_f0.50"
                  src="audio/hifigan/namine_ritsu_BC_seg20_f0.50.wav" controls="" preload=""></audio>
              </td>
              <td style="text-align: center"><audio id="hifigan_f0.71"
                  src="audio/hifigan/namine_ritsu_BC_seg20_f0.71.wav" controls="" preload=""></audio>
              </td>
              <td style="text-align: center"><audio id="hifigan_f1.41"
                  src="audio/hifigan/namine_ritsu_BC_seg20_f1.41.wav" controls="" preload=""></audio>
              </td>
              <td style="text-align: center"><audio id="hifigan_f2.00"
                  src="audio/hifigan/namine_ritsu_BC_seg20_f2.00.wav" controls="" preload=""></audio>
              </td>
            </tr>
            <tr>
              <td style="text-align: left" class="td_fixed">HiFi-GAN<br> + Sine</td>
              <td style="text-align: center"><audio id="hifigan.sine_f1.00"
                  src="audio/hifigan.sine/namine_ritsu_BC_seg20_f1.00.wav" controls="" preload=""></audio>
              </td>
              <td style="text-align: center"><audio id="hifigan.sine_f0.50"
                  src="audio/hifigan.sine/namine_ritsu_BC_seg20_f0.50.wav" controls="" preload=""></audio>
              </td>
              <td style="text-align: center"><audio id="hifigan.sine_f0.71"
                  src="audio/hifigan.sine/namine_ritsu_BC_seg20_f0.71.wav" controls="" preload=""></audio>
              </td>
              <td style="text-align: center"><audio id="hifigan.sine_f1.41"
                  src="audio/hifigan.sine/namine_ritsu_BC_seg20_f1.41.wav" controls="" preload=""></audio>
              </td>
              <td style="text-align: center"><audio id="hifigan.sine_f2.00"
                  src="audio/hifigan.sine/namine_ritsu_BC_seg20_f2.00.wav" controls="" preload=""></audio>
              </td>
            </tr>
            <tr>
              <td style="text-align: left" class="td_fixed">HiFi-GAN<br> + Sine + QP</td>
              <td style="text-align: center"><audio id="hifigan.sine.qp_f1.00"
                  src="audio/hifigan.sine.qp/namine_ritsu_BC_seg20_f1.00.wav" controls="" preload=""></audio>
              </td>
              <td style="text-align: center"><audio id="hifigan.sine.qp_f0.50"
                  src="audio/hifigan.sine.qp/namine_ritsu_BC_seg20_f0.50.wav" controls="" preload=""></audio>
              </td>
              <td style="text-align: center"><audio id="hifigan.sine.qp_f0.71"
                  src="audio/hifigan.sine.qp/namine_ritsu_BC_seg20_f0.71.wav" controls="" preload=""></audio>
              </td>
              <td style="text-align: center"><audio id="hifigan.sine.qp_f1.41"
                  src="audio/hifigan.sine.qp/namine_ritsu_BC_seg20_f1.41.wav" controls="" preload=""></audio>
              </td>
              <td style="text-align: center"><audio id="hifigan.sine.qp_f2.00"
                  src="audio/hifigan.sine.qp/namine_ritsu_BC_seg20_f2.00.wav" controls="" preload=""></audio>
              </td>
            </tr>
            <tr>
              <td style="text-align: left" class="td_fixed"><b>SiFi-GAN</b><br>(Proposed)</td>
              <td style="text-align: center"><audio id="sifigan_f1.00"
                  src="audio/sifigan/namine_ritsu_BC_seg20_f1.00.wav" controls="" preload=""></audio>
              </td>
              <td style="text-align: center"><audio id="sifigan_f0.50"
                  src="audio/sifigan/namine_ritsu_BC_seg20_f0.50.wav" controls="" preload=""></audio>
              </td>
              <td style="text-align: center"><audio id="sifigan_f0.71"
                  src="audio/sifigan/namine_ritsu_BC_seg20_f0.71.wav" controls="" preload=""></audio>
              </td>
              <td style="text-align: center"><audio id="sifigan_f1.41"
                  src="audio/sifigan/namine_ritsu_BC_seg20_f1.41.wav" controls="" preload=""></audio>
              </td>
              <td style="text-align: center"><audio id="sifigan_f2.00"
                  src="audio/sifigan/namine_ritsu_BC_seg20_f2.00.wav" controls="" preload=""></audio>
              </td>
            </tr>
            <tr>
              <td style="text-align: left" class="td_fixed">SiFi-GAN<br>Direct</td>
              <td style="text-align: center"><audio id="sifigan.abl_f1.00"
                  src="audio/sifigan.abl/namine_ritsu_BC_seg20_f1.00.wav" controls="" preload=""></audio>
              </td>
              <td style="text-align: center"><audio id="sifigan.abl_f0.50"
                  src="audio/sifigan.abl/namine_ritsu_BC_seg20_f0.50.wav" controls="" preload=""></audio>
              </td>
              <td style="text-align: center"><audio id="sifigan.abl_f0.71"
                  src="audio/sifigan.abl/namine_ritsu_BC_seg20_f0.71.wav" controls="" preload=""></audio>
              </td>
              <td style="text-align: center"><audio id="sifigan.abl_f1.41"
                  src="audio/sifigan.abl/namine_ritsu_BC_seg20_f1.41.wav" controls="" preload=""></audio>
              </td>
              <td style="text-align: center"><audio id="sifigan.abl_f2.00"
                  src="audio/sifigan.abl/namine_ritsu_BC_seg20_f2.00.wav" controls="" preload=""></audio>
              </td>
            </tr>
          </tbody>
        </table>
      </div>

      <h2 class="sectitle">Citation</h2>
      <div id="citation" class="section">
        <p>@misc{https://doi.org/10.48550/arxiv.2210.15533,<br>
          &nbsp;&nbsp;&nbsp;&nbsp;author = {Reo Yoneyama and Yi-Chiao Wu and Tomoki Toda},<br>
          &nbsp;&nbsp;&nbsp;&nbsp;title = {{Source-Filter HiFi-GAN: Fast and Pitch Controllable High-Fidelity Neural
          Vocoder}},<br>
          &nbsp;&nbsp;&nbsp;&nbsp;year = {2022},<br>
          &nbsp;&nbsp;&nbsp;&nbsp;publisher = {arXiv},<br>
          &nbsp;&nbsp;&nbsp;&nbsp;url = {https://arxiv.org/abs/2210.15533},<br>
          &nbsp;&nbsp;&nbsp;&nbsp;doi = {10.48550/ARXIV.2210.15533},<br>
          &nbsp;&nbsp;&nbsp;&nbsp;copyright = {arXiv.org perpetual, non-exclusive license}<br>
          }
        </p>
      </div>

      <h2 class="sectitle">References</h2>
      <div id="references" class="section">
        <p>[1] J. Kong, J. Kim, and J. Bae, “HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity
          Speech Synthesis,” in Advances in NeurIPS, 2020, vol. 33, pp. 17022–17033.</p>
        <p>[2] Y.-C. Wu, T. Hayashi, T. Okamoto, H. Kawai, and T. Toda, “QuasiPeriodic Parallel WaveGAN: A
          Non-Autoregressive Raw Waveform Generative Model With PitchDependent Dilated Convolution Neural Network,”
          IEEE/ACM TASLP, vol. 29, pp. 792–806, 2021.</p>
        <p>[3] Canon, “[NamineRitsu] Blue (YOASOBI) [ENUNU model Ver.2, Singing DBVer.2 release],”
          https://www.youtube.com/watch?v=pKeo9IE_L1I.
        <p>[4] M. Morise, F. Yokomori, and K. Ozawa, “WORLD: a vocoderbased high-quality speech synthesis system for
          real-time applications,” IEICE Transactions on Information and Systems, vol. 99, no. 7, pp. 1877–1884, 2016.
        </p>
        <p>[5] R. Yoneyama, Y.-C. Wu, and T. Toda, “Unified SourceFilter GAN with Harmonic-plus-Noise Source Excitation
          Generation,” in Proc. Interspeech, 2022, pp. 848–852.</p>
        <p>
          [6] K. Matsubara, T. Okamoto, R. Takashima, T. Takiguchi, T. Toda, and H. Kawai, “Period-HiFi-GAN: Fast and
          fundamental frequency controllable neural vocoder,” in Proc. Acoustical Society of Japan, in Japanese, Mar.
          2022, pp. 901–904.
        </p>
        <p>[7] S. Shimizu, T. Okamoto, R. Takashima, T. Takiguchi, T. Toda, H. Kawai, “Initial investigation of
          fundamental frequency controllable HiFi-GAN conditioned on mel-spectrogram,” in Acoustical Society of Japan,
          Sep. 2022, pp. 1137–1140.</p>
        <p>[8] K. Matsubara, T. Okamoto, R. Takashima, T. Takiguchi, T. Toda, H. Kawai, “Hamonic-Net+: Fundamental
          frequency controllable fast neural vocoder with harmonic wave input and Layerwise-Quasi-Periodic CNNs,” in
          Acoustical Society of Japan, Sep. 2022, pp. 1133–1136.</p>
      </div>

    </div>

    <div class="page-top" id="js-page-top">
      <span class="material-icons-outlined">expand_less</span>
    </div>

    <footer>
      <a class="copyright">Copyright&copy;2022.</a>
      <a href="https://github.com/chomeyama/" target="_blank">
        <img class="icon" src="img/github_icon.png" alt="GitHub icon">
      </a>
      <a href="https://twitter.com/_riceham/" target="_blank">
        <img class="icon" src="img/twitter_icon.png" alt="Twitter icon">
      </a>
    </footer>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script type='text/javascript' src="js/script.js"></script>
</body>

</html>